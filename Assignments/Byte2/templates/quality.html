<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="favicon.ico">
    <title>Quality of This Data</title>

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <!-- Bootstrap theme -->
    <link href="css/bootstrap-theme.min.css" rel="stylesheet">
    <!-- Custom styles for this template -->
    <link href="css/theme.css" rel="stylesheet">
  </head>

  <body role="document">

    <!-- Fixed navbar -->
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="/">Home</a></li>
            <li><a href="about">About This Data Set</a></li>
	    <li  class="active"><a href="quality">Data Quality</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container theme-showcase" role="main">

      <!-- Main jumbotron for a primary marketing message or call to action -->
      <div class="jumbotron">
	<h1>Quality: About This Data Set</h1>
        <p>This dataset has problems in terms of completeness, coherency, and correctness. Firstly, the data contains missing data of important features, like rating of a specific app. Second, the data is not coherent
           in a way that it contains duplicate values. On the other hand, the range of features is relatively reasonable. Moreover, the data is incorrect since it has underlying problem of sample bias since the age distribution
           of the raters can be uneven, and the ratings of different ages are exactly distinct. It also brings bias in within different categories, reminding us that we should evaluate apps within genres.</a></p>
      </div>

    
      <div class="page-header">
	<h2>Is the data complete?</h2>
	<p>
	In terms of appropriate data, the dataset contains sufficient and adequate information for us to evaluate apps on GooglePlay and give recommendation list. For example, we can judge whether an app is 
	polular or not by "Installs" and "Reviews", or one has a good reputation or not by "Rating".<br>
	However, I detect missing values in the dataset, therefore undermining the completeness of the data. 
	As is indicated in the NaN analyzing result by Pandas on raw data, the following columns --- “Rating”, “Reviews”, “Type”, “Price”, “Current Ver”, “Android Ver” 
	all contains NaN values. It can be devastating when visualizing those columns, since the NaNs are nonsense compared to numeric values or categorical values. 
	For example, if I would like to plot the histogram of Ratings, the NaN values can undermine the correctness of the overall distribution of app ratings.<p/>
	
	<center>
	  <img src="http://gdurl.com/OSKw" alt="nan" style="width:90%">
	</center>
	<br>
	<p>I decide to use a simple dropping method to handle NaNs, yet I realized if I dropped all rows containing at least one NaN, the remaining entries number will only be 7616. 
	As is depicted from the table, most NaNs appears at the column of "Android Ver", yet this column has nothing to do with our question. After removing this column, there's only 1147 rows containing at least one 
	NaN, now I can simply drop all lines with NaNs, and move on to the next stage. <br>
	To sum up, the data is not complete since it contains missing data in very important features. I handle this problem by deleting unrelevant columns that contains most of the missing values, then
	drop all entries with missing values.</p>
      </div>
	      
      <div class="page-header">
	<h2>Is the data coherent?</h2>
	<p>The first issue on coherency is the <b>duplicate data</b>. I first check if this there is any duplicate rows by counting the time of different apps.
	The result indicates that several apps appears more than once. The following table calculate the count of entries, we can see that several apps appears more than ones, some even with same ratings. Therefore I dropped 
	all duplicates and only keep the first entry. Besides, In this case, we can say that the raw data is not coherent in the way of duplication.</p>
	<center>
		<img src="http://gdurl.com/d-5v" alt="duplicate" style="width:30%">
	</center>
	<br>
	<p>
	Next, I check if the data makes sense in terms of <b>data type and range</b>. It can be summarized from the table below that several columns depict wrong data type, noticing that "object type" is the same for "string type" in
	pandas. String type is adequate for features like version, category, yet it shouldn't be the right choice for numerical values like ratings and install numbers. Therefore, I convert the column of "Rating" and "Price" 
	into numeric values, and it's quite helpful for the coming visualization of these features.
	</p>
	<center>
		<img src="http://gdurl.com/r6Ib" alt="dtype" style="width:30%">
	</center>
	<p>Then, I select severval columns for demonstration to check whether the data range makes sense since it might be a tough work to illustrate everything in detail on the webpage.
	First, I choose the column "Rating", the most significant value to make evaluation, and make a histogram. 
	We can see that the ratings are among 0 to 5, which is noraml for app ratings, and the mean is around 4.17, which is also intuitive.</p>
	<center>
		<img src="http://gdurl.com/VaX5o" alt="rating" style="width:50%">
	</center>
	<br>  
	<p>
	Apart from that, I demonstrate the distribution of "Price". Since most of the apps are free, I only plot the histogram of paid apps. The histogram conveys that most of the price tags fall in the range between 0 and 50,
	which is in common sense, yet some observations are tend to act as outliers with a very expensive price.</p>

	<center>
		<img src="http://gdurl.com/4Fq7" alt="price" style="width:50%">
	</center>
	
	<p>
	To check what these apps are, I selected entries that get a price of 200 dollars and above. Interestingly, these entries seems to be similar with each other, all refering to something named as "I'm rich". It is said to
	be one of the strangest apps avaliable, so probably we should say the price is reasonable.
	</p>
	<center>
		<img src="http://gdurl.com/lcuK" alt="rich" style="width:80%">
	</center>
	<p>Similarly I checked the other columns, finding the value is relatively reasonable, so we can say that those columns are in accordance with coherence.</p>
    </div>
	

      <div class="page-header">
	<h2>Is the data correct?</h2>
	<p>
	Considering the correctness of data, typical issues can be <b>sample bias</b>, <b>measurement error</b>, <b>fradulent data</b> as well as <b>implementation issues</b>.<br>
    First, let's look at sample bias within population. Assume the value we focus on is "Rating". The "Content Rating" column is responsible for the distribution of population who rate the apps.
	We can see from the pie char that more than 80% of the population is labeled as "everyone", which makes it very hard to determine the age distribution of the overall population. 
	</p>
	<center>
		<img src="http://gdurl.com/c47k" alt="popu" style="width:60%">
	</center>
	<p>To determine whether population within different ages results in bias, I plot the distribution of ratings of two labeled group --- "Mature" and "Teen", and compare them with the overall distribution. </p>
	<center>
		<img src="http://gdurl.com/XJbx" alt="age" style="width:80%">
	</center>
	<p>
	It can be observed that the rating distribution is obviously different between mature group and teen group, with a average rating of 4.12 and 4.23. Therefore, we can conclude that the data has potential problem of sample bias among population, 
	since we don't know whether the ratings are sampled according to the proportion of people at different stage of a specific app.<br>
	Besides, I also notice that ratings can be quite different among different categories. If we simply mix the ratings of different categories, the analyzed result can be misleading since we neglect the bias within genres.
	To further confirm this point, I plot rating histogram among different groups. The distributions have obvious distinctions, therfore we have to evaluate apps within a category instead of all data, which make sense with
	respect to making recommendation of apps in a specific type.</p>
	<center>
		<img src="http://gdurl.com/ZuEzZ" alt="age" style="width:100%">
	</center>	
	<p>As for other issue, like measurement error, it is quite possible some people fabricate a rating since lots of rating mechanism is rating by interuption when users are experiencing the app. 
	People may tend to give a quick review without full consideration. This may lead to the potential incorrectness of the data. However, this information cannot be directly revealed from the given data.<br>
	In a nut shell, as is indicated by the data, potential incorrectness in sampling bias occurs due to the insufficient knowledge on the age distributions of users. Category brings about great sample bias of different
	groups. Other correctness issues cannot be directed inferred from the data.</p>
	
      </div>

    </div> <!-- /container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="js/jquery-1.11.3.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/docs.min.js"></script>
  </body>
</html>
